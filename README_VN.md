# WhisperLib - Th∆∞ vi·ªán Speech Recognition cho Android

[![Android](https://img.shields.io/badge/Android-3DDC84?style=for-the-badge&logo=android&logoColor=white)](https://developer.android.com/)
[![Kotlin](https://img.shields.io/badge/Kotlin-0095D5?&style=for-the-badge&logo=kotlin&logoColor=white)](https://kotlinlang.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=TensorFlow&logoColor=white)](https://tensorflow.org/)

WhisperLib l√† m·ªôt th∆∞ vi·ªán Android m·∫°nh m·∫Ω ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n TensorFlow Lite, cho ph√©p b·∫°n t√≠ch h·ª£p t√≠nh nƒÉng nh·∫≠n d·∫°ng gi·ªçng n√≥i (Speech Recognition) v√†o ·ª©ng d·ª•ng Android m·ªôt c√°ch d·ªÖ d√†ng v√† hi·ªáu qu·∫£.

## ‚ú® T√≠nh nƒÉng

- üé§ **Ghi √¢m real-time** v·ªõi ch·∫•t l∆∞·ª£ng cao
- üß† **Nh·∫≠n d·∫°ng gi·ªçng n√≥i** s·ª≠ d·ª•ng m√¥ h√¨nh Whisper
- üåç **H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ** (Multilingual)
- ‚ö° **Hi·ªáu su·∫•t cao** v·ªõi native C++ engine
- üîß **API ƒë∆°n gi·∫£n** v√† d·ªÖ s·ª≠ d·ª•ng
- üì± **T∆∞∆°ng th√≠ch** v·ªõi Android API 29+

## üìã Y√™u c·∫ßu h·ªá th·ªëng

- **Android API Level**: 29+ (Android 10+)
- **Architecture**: ARM64-v8a, ARMv7
- **RAM**: T·ªëi thi·ªÉu 2GB
- **Storage**: ~50MB cho model v√† th∆∞ vi·ªán

## üöÄ C√†i ƒë·∫∑t

### B∆∞·ªõc 1: Th√™m AAR v√†o project

1. T·∫£i file `whisper-lib-release.aar` t·ª´ [Releases](../../releases)
2. Copy file v√†o th∆∞ m·ª•c `libs` trong project c·ªßa b·∫°n:
   ```
   app/libs/whisper-lib-release.aar
   ```

### B∆∞·ªõc 2: C·∫•u h√¨nh build.gradle

Th√™m v√†o file `app/build.gradle.kts`:

```kotlin
android {
    // ... existing configuration
    
    packagingOptions {
        pickFirst '**/libc++_shared.so'
        pickFirst '**/libjsc.so'
    }
}

dependencies {
    // WhisperLib AAR
    implementation(files("libs/whisper-lib-release.aar"))
    
    // Ho·∫∑c s·ª≠ d·ª•ng fileTree
    implementation(fileTree(mapOf("dir" to "libs", "include" to listOf("*.aar"))))
    
    // Required dependencies
    implementation("androidx.appcompat:appcompat:1.6.1")
    implementation("org.tensorflow:tensorflow-lite:2.14.0")
    implementation("org.tensorflow:tensorflow-lite-support:0.4.4")
}
```

### B∆∞·ªõc 3: Th√™m permissions

Th√™m v√†o `AndroidManifest.xml`:

```xml
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" />
<uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" />
```

### B∆∞·ªõc 4: Y√™u c·∫ßu permissions runtime

```kotlin
class MainActivity : AppCompatActivity() {
    private val REQUEST_RECORD_AUDIO = 1001
    
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        
        // Y√™u c·∫ßu quy·ªÅn ghi √¢m
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) 
            != PackageManager.PERMISSION_GRANTED) {
            ActivityCompat.requestPermissions(this, 
                arrayOf(Manifest.permission.RECORD_AUDIO), REQUEST_RECORD_AUDIO)
        }
    }
    
    override fun onRequestPermissionsResult(
        requestCode: Int, 
        permissions: Array<String>, 
        grantResults: IntArray
    ) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == REQUEST_RECORD_AUDIO) {
            if (grantResults.isNotEmpty() && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                // Quy·ªÅn ƒë√£ ƒë∆∞·ª£c c·∫•p, c√≥ th·ªÉ s·ª≠ d·ª•ng WhisperLib
            }
        }
    }
}
```

## üìñ C√°ch s·ª≠ d·ª•ng

### Kh·ªüi t·∫°o WhisperLib

```kotlin
import com.hadtun.whisperlib.WhisperLib

class MainActivity : AppCompatActivity() {
    private lateinit var whisperLib: WhisperLib
    
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        
        // Kh·ªüi t·∫°o WhisperLib
        whisperLib = WhisperLib.init(this)
        
        // Load model m·∫∑c ƒë·ªãnh
        val success = whisperLib.loadDefaultModel()
        if (success) {
            Log.d("WhisperLib", "Model loaded successfully")
        }
    }
}
```

### Ghi √¢m v√† nh·∫≠n d·∫°ng gi·ªçng n√≥i

```kotlin
class VoiceRecognitionActivity : AppCompatActivity() {
    private lateinit var whisperLib: WhisperLib
    
    private fun startRecording() {
        val success = whisperLib.startRecording()
        if (success) {
            Log.d("VoiceRecognition", "Recording started")
            // C·∫≠p nh·∫≠t UI ƒë·ªÉ hi·ªÉn th·ªã tr·∫°ng th√°i ƒëang ghi √¢m
        }
    }
    
    private fun stopRecording() {
        val success = whisperLib.stopRecording()
        if (success) {
            Log.d("VoiceRecognition", "Recording stopped")
            
            // L·∫•y k·∫øt qu·∫£ nh·∫≠n d·∫°ng
            val transcription = whisperLib.getTranscription()
            Log.d("VoiceRecognition", "Transcription: $transcription")
            
            // Hi·ªÉn th·ªã k·∫øt qu·∫£ l√™n UI
            updateUI(transcription)
        }
    }
    
    private fun updateUI(text: String) {
        runOnUiThread {
            // C·∫≠p nh·∫≠t TextView v·ªõi k·∫øt qu·∫£
            textViewResult.text = text
        }
    }
}
```

### S·ª≠ d·ª•ng v·ªõi Button Press-and-Hold

```kotlin
class ChatActivity : AppCompatActivity() {
    private lateinit var whisperLib: WhisperLib
    
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_chat)
        
        whisperLib = WhisperLib.init(this)
        whisperLib.loadDefaultModel()
        
        setupChatButton()
    }
    
    private fun setupChatButton() {
        val chatButton = findViewById<Button>(R.id.btnChat)
        
        chatButton.setOnTouchListener { _, event ->
            when (event.action) {
                MotionEvent.ACTION_DOWN -> {
                    // B·∫Øt ƒë·∫ßu ghi √¢m khi nh·∫•n v√† gi·ªØ
                    whisperLib.startRecording()
                    chatButton.setBackgroundColor(Color.RED)
                    true
                }
                MotionEvent.ACTION_UP, MotionEvent.ACTION_CANCEL -> {
                    // D·ª´ng ghi √¢m v√† nh·∫≠n d·∫°ng khi th·∫£ n√∫t
                    whisperLib.stopRecording()
                    chatButton.setBackgroundColor(Color.BLUE)
                    
                    // L·∫•y k·∫øt qu·∫£ v√† hi·ªÉn th·ªã
                    val result = whisperLib.getTranscription()
                    displayResult(result)
                    true
                }
                else -> false
            }
        }
    }
    
    private fun displayResult(text: String) {
        runOnUiThread {
            textViewResult.text = text
        }
    }
}
```

### Nh·∫≠n d·∫°ng t·ª´ file audio

```kotlin
class AudioFileActivity : AppCompatActivity() {
    private lateinit var whisperLib: WhisperLib
    
    private fun transcribeAudioFile(filePath: String) {
        // Nh·∫≠n d·∫°ng t·ª´ file audio c√≥ s·∫µn
        val result = whisperLib.transcribeFile(filePath)
        
        if (result.isNotEmpty()) {
            Log.d("AudioFile", "Transcription: $result")
            // X·ª≠ l√Ω k·∫øt qu·∫£
        } else {
            Log.e("AudioFile", "Transcription failed")
        }
    }
}
```

### Ki·ªÉm tra tr·∫°ng th√°i

```kotlin
class StatusActivity : AppCompatActivity() {
    private lateinit var whisperLib: WhisperLib
    
    private fun checkStatus() {
        // Ki·ªÉm tra xem c√≥ ƒëang ghi √¢m kh√¥ng
        val isRecording = whisperLib.isRecording()
        
        // L·∫•y ƒë∆∞·ªùng d·∫´n file audio ƒë√£ ghi
        val audioPath = whisperLib.getRecordedAudioPath()
        
        Log.d("Status", "Is recording: $isRecording")
        Log.d("Status", "Audio path: $audioPath")
    }
    
    override fun onDestroy() {
        super.onDestroy()
        // Gi·∫£i ph√≥ng t√†i nguy√™n
        whisperLib.release()
    }
}
```

## üîß API Reference

### WhisperLib Class

#### Methods ch√≠nh:

| Method | M√¥ t·∫£ | Return Type |
|--------|-------|-------------|
| `init(context)` | Kh·ªüi t·∫°o WhisperLib | `WhisperLib` |
| `loadDefaultModel()` | Load model m·∫∑c ƒë·ªãnh | `Boolean` |
| `loadModel(path, isMultilingual)` | Load model t√πy ch·ªânh | `Boolean` |
| `startRecording()` | B·∫Øt ƒë·∫ßu ghi √¢m | `Boolean` |
| `stopRecording()` | D·ª´ng ghi √¢m | `Boolean` |
| `getTranscription()` | L·∫•y k·∫øt qu·∫£ nh·∫≠n d·∫°ng | `String` |
| `transcribeFile(filePath)` | Nh·∫≠n d·∫°ng t·ª´ file | `String` |
| `isRecording()` | Ki·ªÉm tra tr·∫°ng th√°i ghi √¢m | `Boolean` |
| `getRecordedAudioPath()` | L·∫•y ƒë∆∞·ªùng d·∫´n file audio | `String?` |
| `release()` | Gi·∫£i ph√≥ng t√†i nguy√™n | `Unit` |

#### V√≠ d·ª• s·ª≠ d·ª•ng ƒë·∫ßy ƒë·ªß:

```kotlin
class CompleteExample : AppCompatActivity() {
    private lateinit var whisperLib: WhisperLib
    
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        
        // 1. Kh·ªüi t·∫°o
        whisperLib = WhisperLib.init(this)
        
        // 2. Load model
        val modelLoaded = whisperLib.loadDefaultModel()
        if (!modelLoaded) {
            Log.e("WhisperLib", "Failed to load model")
            return
        }
        
        // 3. Setup UI
        setupUI()
    }
    
    private fun setupUI() {
        val recordButton = findViewById<Button>(R.id.btnRecord)
        val resultText = findViewById<TextView>(R.id.tvResult)
        
        recordButton.setOnClickListener {
            if (whisperLib.isRecording()) {
                // D·ª´ng ghi √¢m
                whisperLib.stopRecording()
                val result = whisperLib.getTranscription()
                resultText.text = result
                recordButton.text = "Start Recording"
            } else {
                // B·∫Øt ƒë·∫ßu ghi √¢m
                whisperLib.startRecording()
                recordButton.text = "Stop Recording"
            }
        }
    }
    
    override fun onDestroy() {
        super.onDestroy()
        whisperLib.release()
    }
}
```

## üéØ C√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng

### 1. Voice Notes App
```kotlin
// Ghi √¢m v√† chuy·ªÉn th√†nh text note
whisperLib.startRecording()
// ... sau khi ng∆∞·ªùi d√πng n√≥i xong
whisperLib.stopRecording()
val note = whisperLib.getTranscription()
saveNoteToDatabase(note)
```

### 2. Voice Search
```kotlin
// T√¨m ki·∫øm b·∫±ng gi·ªçng n√≥i
whisperLib.startRecording()
// ... ng∆∞·ªùi d√πng n√≥i t·ª´ kh√≥a t√¨m ki·∫øm
whisperLib.stopRecording()
val searchQuery = whisperLib.getTranscription()
performSearch(searchQuery)
```

### 3. Voice Commands
```kotlin
// ƒêi·ªÅu khi·ªÉn ·ª©ng d·ª•ng b·∫±ng gi·ªçng n√≥i
whisperLib.startRecording()
// ... ng∆∞·ªùi d√πng n√≥i l·ªánh
whisperLib.stopRecording()
val command = whisperLib.getTranscription()
executeVoiceCommand(command)
```

### 4. Real-time Transcription
```kotlin
// Chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i th√†nh text real-time
whisperLib.startRecording()
// C√≥ th·ªÉ s·ª≠ d·ª•ng timer ƒë·ªÉ nh·∫≠n d·∫°ng ƒë·ªãnh k·ª≥
val timer = Timer()
timer.scheduleAtFixedRate(object : TimerTask() {
    override fun run() {
        if (whisperLib.isRecording()) {
            val partialResult = whisperLib.getTranscription()
            updateRealtimeUI(partialResult)
        }
    }
}, 0, 2000) // M·ªói 2 gi√¢y
```

## ‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng

### Performance
- **L·∫ßn ƒë·∫ßu load model**: C√≥ th·ªÉ m·∫•t 2-5 gi√¢y
- **Th·ªùi gian nh·∫≠n d·∫°ng**: 1-3 gi√¢y t√πy thu·ªôc ƒë·ªô d√†i audio
- **RAM usage**: ~100-200MB khi ho·∫°t ƒë·ªông
- **Battery**: Ti√™u t·ªën pin khi ghi √¢m li√™n t·ª•c

### Best Practices
1. **Lu√¥n ki·ªÉm tra permissions** tr∆∞·ªõc khi s·ª≠ d·ª•ng
2. **Release resources** trong `onDestroy()`
3. **X·ª≠ l√Ω l·ªói** khi load model ho·∫∑c ghi √¢m
4. **Test tr√™n device th·∫≠t** ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng audio
5. **S·ª≠ d·ª•ng background thread** cho c√°c t√°c v·ª• n·∫∑ng

### Troubleshooting

#### L·ªói th∆∞·ªùng g·∫∑p:

**1. "Permission denied"**
```kotlin
// Gi·∫£i ph√°p: Ki·ªÉm tra v√† y√™u c·∫ßu quy·ªÅn
if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) 
    != PackageManager.PERMISSION_GRANTED) {
    ActivityCompat.requestPermissions(this, 
        arrayOf(Manifest.permission.RECORD_AUDIO), REQUEST_CODE)
}
```

**2. "Model not loaded"**
```kotlin
// Gi·∫£i ph√°p: Ki·ªÉm tra model path v√† file t·ªìn t·∫°i
val success = whisperLib.loadDefaultModel()
if (!success) {
    Log.e("WhisperLib", "Check if model files exist in assets")
}
```

**3. "No audio input"**
```kotlin
// Gi·∫£i ph√°p: Ki·ªÉm tra microphone v√† audio settings
if (!whisperLib.isRecording()) {
    Log.e("WhisperLib", "Check microphone permissions and hardware")
}
```

## üì± Demo App

Xem th√™m v√≠ d·ª• chi ti·∫øt trong th∆∞ m·ª•c `demo/` v·ªõi c√°c t√≠nh nƒÉng:
- Basic voice recording
- Press-and-hold chat button
- File audio transcription
- Real-time voice commands

## ü§ù ƒê√≥ng g√≥p

Ch√∫ng t√¥i hoan ngh√™nh m·ªçi ƒë√≥ng g√≥p! H√£y:

1. Fork repository
2. T·∫°o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. T·∫°o Pull Request

## üìÑ License

Distributed under the MIT License. See `LICENSE` for more information.

## üìû Li√™n h·ªá

- **GitHub Issues**: [T·∫°o issue](../../issues)

## üôè Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper) - M√¥ h√¨nh nh·∫≠n d·∫°ng gi·ªçng n√≥i
- [TensorFlow Lite](https://www.tensorflow.org/lite) - Framework machine learning
- [Android AudioRecord](https://developer.android.com/reference/android/media/AudioRecord) - API ghi √¢m Android

---

‚≠ê **N·∫øu th∆∞ vi·ªán n√†y h·ªØu √≠ch, h√£y cho ch√∫ng t√¥i m·ªôt star!** ‚≠ê
